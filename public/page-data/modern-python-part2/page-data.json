{"componentChunkName":"component---src-pages-markdown-remark-fields-slug-js","path":"/modern-python-part2/","result":{"data":{"markdownRemark":{"html":"<p>Good software engineering practices always bring a lot of long-term benefits. For example, writing unit tests permits you to maintain large codebases and ensures that a specific piece of your code behaves as expected. Writing consistent Git commits also enhance the collaboration between the project stakeholders. Well-crafted Git commit messages open the door to automatic versioning and generated change log files. Consequently, a lot of attempts are currently ongoing and applied to normalize the messages written in our Git commits.</p>\n<p>In the first part of this serie, we setup, our project by installing different Python versions with <code>pyenv</code>, setting a local version of Python with <code>pyenv</code>, encapsulating it into a virtual environment with <code>poetry</code>. Here we show more precisely how to unit test your Python application and how to enforce and validate your Git commit messages. The source code associated with this article is published on <a href=\"https://github.com/adaltas/summarize_dataframe\">GitHub</a>.</p>\n<h2 id=\"testing-our-code\" style=\"position:relative;\"><a href=\"#testing-our-code\" aria-label=\"testing our code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Testing our code</h2>\n<p>The project is a simple python function that summarizes data present in a <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\">pandas DataFrame</a>. The function outputs the number of rows and columns and the frequency of each data types present in the pandas DataFrame:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">---- Data Summary ------\n                       Values\nNumber of rows          <span class=\"token number\">230</span>\nNumber of columns         <span class=\"token number\">9</span>\nfloat64                   <span class=\"token number\">3</span>\nint64                     <span class=\"token number\">4</span>\nobject                    <span class=\"token number\">2</span></code></pre></div>\n<p>Go to your project root directory and activate your virtual environment:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry shell</code></pre></div>\n<p>We add a couple of dependencies using poetry:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry <span class=\"token function\">add</span> <span class=\"token parameter variable\">-D</span> pynvim numpy pandas\n\nUsing version ^0.4.3 <span class=\"token keyword\">for</span> pynvim\nUsing version ^1.20.2 <span class=\"token keyword\">for</span> numpy\nUsing version ^1.2.3 <span class=\"token keyword\">for</span> pandas\n\nUpdating dependencies\nResolving dependencies<span class=\"token punctuation\">..</span>. <span class=\"token punctuation\">(</span><span class=\"token number\">1</span>.4s<span class=\"token punctuation\">)</span>\n\nWriting lock <span class=\"token function\">file</span>\n\nPackage operations: <span class=\"token number\">8</span> installs, <span class=\"token number\">0</span> updates, <span class=\"token number\">0</span> removals\n\n  • Installing six <span class=\"token punctuation\">(</span><span class=\"token number\">1.15</span>.0<span class=\"token punctuation\">)</span>\n  • Installing greenlet <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span>.0<span class=\"token punctuation\">)</span>\n  • Installing msgpack <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span>.2<span class=\"token punctuation\">)</span>\n  • Installing numpy <span class=\"token punctuation\">(</span><span class=\"token number\">1.20</span>.2<span class=\"token punctuation\">)</span>\n  • Installing python-dateutil <span class=\"token punctuation\">(</span><span class=\"token number\">2.8</span>.1<span class=\"token punctuation\">)</span>\n  • Installing pytz <span class=\"token punctuation\">(</span><span class=\"token number\">2021.1</span><span class=\"token punctuation\">)</span>\n  • Installing pandas <span class=\"token punctuation\">(</span><span class=\"token number\">1.2</span>.3<span class=\"token punctuation\">)</span>\n  • Installing pynvim <span class=\"token punctuation\">(</span><span class=\"token number\">0.4</span>.3<span class=\"token punctuation\">)</span></code></pre></div>\n<p>The <code>-D</code> flag indicates that the dependency only apply to development environments.</p>\n<blockquote>\n<p>Note: I personally use NeoVim for coding that is why I need the <code>pynvim</code>  package to support NeoVim python plugins.</p>\n</blockquote>\n<p>Based on the expected output defined above, our program is made of three steps:</p>\n<ol>\n<li>Getting the shape of the pandas DataFrame.</li>\n<li>Getting the pandas <code>dtypes</code> frequency.</li>\n<li>Concatenating the two results into a unified DataFrame that we will use to output the final result.</li>\n</ol>\n<p>Once the final DataFrame is obtained we output the result as depicted above. In this regard our code scaffold could look as the following:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">data_summary</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Function defined to return a DataFrame containing details\n    about the number of rows and columns and the column dtype\n    frequency of the passed pandas DataFrame\n    \"\"\"</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_shape</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        Function defined to return a dataframe with details about\n        the number of row and columns\n        \"\"\"</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">None</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_dtypes_freq</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        Function defined to return a dataframe with details about\n        the pandas dtypes frequency\n        \"\"\"</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">None</span>\n\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">display_summary</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Function define to print out the result of the data summary\n    \"\"\"</span>\n    result_df <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n    message <span class=\"token operator\">=</span> <span class=\"token string\">'---- Data summary ----'</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">,</span> result_df<span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Let's now start writing our unit tests. We are going to use the <code>unittest</code> tool available with the Python standard library. You may remember in the previous article that <a href=\"https://docs.pytest.org/en/stable/contents.html\">pytest</a> was defined as a developer dependency for testing. It is not an issue with <code>pytest</code> because it natively runs tests written with the <code>unittest</code> library.</p>\n<p>Unit tests are single methods that <code>unittest</code> expects you to write inside Python classes. Choose a descriptive name for your test classes and methods. The name of your test methods should start with <code>test_</code>.  Additionally, <code>unittest</code> uses a series of special assertion methods inherited from the <code>unittest.TestCase</code> class. In practice, a test should precisely cover one feature, be autonomous without requiring external cues, and should recreate the conditions of their success.</p>\n<p>To recreate the necessary environment, setup code must be written. If this code happens to be redundant, implements a <code>setUp()</code> method, that will be executed before every single test. This is pretty convenient to re-use and re-organize your code. Depending on your use case you may have to perform systematic operations after the tests ran. For that, you may use the <code>tearDown()</code> method.</p>\n<p>First you can read below the unit test we implemented for the <code>data_summary()</code> function:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> unittest\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> summarize_dataframe<span class=\"token punctuation\">.</span>summarize_df <span class=\"token keyword\">import</span> data_summary\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">TestDataSummary</span><span class=\"token punctuation\">(</span>unittest<span class=\"token punctuation\">.</span>TestCase<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">setUp</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># initialize dataframe to test</span>\n        df_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'c'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n        df_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'numbers'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'letters'</span><span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>df_data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>df_cols<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># initialize expected dataframe</span>\n        exp_col <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Values'</span><span class=\"token punctuation\">]</span>\n        exp_idx <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Number of rows'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Number of columns'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'int64'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'object'</span><span class=\"token punctuation\">]</span>\n        exp_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>exp_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>exp_data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>exp_col<span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span>exp_idx<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_data_summary</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        expected_df <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>exp_df\n        result_df <span class=\"token operator\">=</span> data_summary<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>assertTrue<span class=\"token punctuation\">(</span>expected_df<span class=\"token punctuation\">.</span>equals<span class=\"token punctuation\">(</span>result_df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    unittest<span class=\"token punctuation\">.</span>main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>The <code>setUp()</code> method initializes two distinct pandas DataFrame. <code>self.exp_df</code> is the resulting DataFrame we expect to get after calling the <code>data_summary()</code> function and <code>self.df</code> is the one used to test our functions. At the moment, tests are expected to fail. The logic has not been implemented. To test with <code>poetry</code> use the command:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry run pytest <span class=\"token parameter variable\">-v</span>\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span> <span class=\"token builtin class-name\">test</span> session starts <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span>\nplatform linux -- Python <span class=\"token number\">3.8</span>.7, pytest-5.4.3, py-1.10.0, pluggy-0.13.1 -- /home/fbraza/.cache/pypoetry/virtualenvs/summarize-dataframe-SO-g_7pj-py3.8/bin/python\ncachedir: .pytest_cache\nrootdir: /home/fbraza/Documents/python_project/summarize_dataframe\ncollected <span class=\"token number\">1</span> item\ntests/test_summarize_dataframe.py::TestDataSummary::test_data_summary FAILED <span class=\"token punctuation\">[</span><span class=\"token number\">100</span>%<span class=\"token punctuation\">]</span>\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span> FAILURES <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span>\n___________________________________TestDataSummary.test_data_summary _____________________________\n\nself <span class=\"token operator\">=</span> <span class=\"token operator\">&lt;</span>tests.test_summarize_dataframe.TestDataSummary <span class=\"token assign-left variable\">testMethod</span><span class=\"token operator\">=</span>test_data_summary<span class=\"token operator\">></span>\n\n    def test_data_summary<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span>:\n        expected_df <span class=\"token operator\">=</span> self.exp_df\n        result_df <span class=\"token operator\">=</span> data_summary<span class=\"token punctuation\">(</span>self.df<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">></span>       self.assertTrue<span class=\"token punctuation\">(</span>expected_df.equals<span class=\"token punctuation\">(</span>result_df<span class=\"token punctuation\">))</span>\nE       AssertionError: False is not <span class=\"token boolean\">true</span>\n\ntests/test_summarize_dataframe.py:26: AssertionError\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span> short <span class=\"token builtin class-name\">test</span> summary info <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span>\nFAILED tests/test_summarize_dataframe.py::TestDataSummary::test_data_summary - AssertionError: False is not <span class=\"token boolean\">true</span>\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span> <span class=\"token number\">1</span> failed <span class=\"token keyword\">in</span> <span class=\"token number\">0</span>.32s <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span></code></pre></div>\n<p>Using the <code>-v</code> flag returns a more verbose output for your test results. You can see that your tests are labeled according to the classes and functions names you gave (i.e., <code>&#x3C;test_module.py>::&#x3C;class>::&#x3C;test_method></code>).</p>\n<p>The code is updated to conform with the unit tests:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">data_summary</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Function defined to output details about the number\n    of rows and columns and the column dtype frequency of\n    the passed pandas DataFrame\n    \"\"\"</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_shape</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        Function defined to return a dataframe with details about\n        the number of row and columns\n        \"\"\"</span>\n        row<span class=\"token punctuation\">,</span> col <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>shape\n        <span class=\"token keyword\">return</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Values'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Number of rows'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Number of columns'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_dtypes_freq</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        Function defined to return a dataframe with details about\n        the pandas dtypes frequency\n        \"\"\"</span>\n        counter<span class=\"token punctuation\">,</span> types <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> df<span class=\"token punctuation\">.</span>dtypes\n        <span class=\"token keyword\">for</span> dtype <span class=\"token keyword\">in</span> types<span class=\"token punctuation\">:</span>\n            tmp <span class=\"token operator\">=</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>dtype<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> tmp <span class=\"token keyword\">in</span> counter<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                counter<span class=\"token punctuation\">[</span>tmp<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                counter<span class=\"token punctuation\">[</span>tmp<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n        values <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>value<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> value <span class=\"token keyword\">in</span> counter<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">return</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>values<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Values'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>counter<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    result_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>_shape<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> _dtypes_freq<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> result_df\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">display_summary</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Function define to print out the result of the data summary\n    \"\"\"</span>\n    result_df <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n    message <span class=\"token operator\">=</span> <span class=\"token string\">'---- Data summary ----'</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">,</span> result_df<span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Run our test again:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry run pytest <span class=\"token parameter variable\">-v</span>\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span> <span class=\"token builtin class-name\">test</span> session starts <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span>\nplatform linux -- Python <span class=\"token number\">3.8</span>.7, pytest-5.4.3, py-1.10.0, pluggy-0.13.1 -- /home/fbraza/.cache/pypoetry/virtualenvs/summarize-dataframe-SO-g_7pj-py3.8/bin/python\ncachedir: .pytest_cache\nrootdir: /home/fbraza/Documents/python_project/summarize_dataframe\ncollected <span class=\"token number\">1</span> item\n\ntests/test_summarize_dataframe.py::TestDataSummary::test_data_summary PASSED <span class=\"token punctuation\">[</span><span class=\"token number\">100</span>%<span class=\"token punctuation\">]</span>\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span> <span class=\"token number\">1</span> passed <span class=\"token keyword\">in</span> <span class=\"token number\">0</span>.28s <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span></code></pre></div>\n<p>One last thing here. In our tests, we did not test the actual output. Our module is designed to output a string representation of our DataFrame summary. There are solutions to achieve this goal with <code>unittest</code>. However we are going to use <code>pytest</code> for this test. Surprising isn't it? As said before <code>pytest</code> interpolates very well with <code>unittest</code> and we are going to illustrate it now. Here the code for this test:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> unittest\n<span class=\"token keyword\">import</span> pytest\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> summarize_dataframe<span class=\"token punctuation\">.</span>summarize_df <span class=\"token keyword\">import</span> data_summary<span class=\"token punctuation\">,</span> display_summary\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">TestDataSummary</span><span class=\"token punctuation\">(</span>unittest<span class=\"token punctuation\">.</span>TestCase<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">setUp</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># initialize dataframe to test</span>\n        df_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'c'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n        df_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'numbers'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'letters'</span><span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>df_data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>df_cols<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># initialize expected dataframe</span>\n        exp_col <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Values'</span><span class=\"token punctuation\">]</span>\n        exp_idx <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Number of rows'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Number of columns'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'int64'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'object'</span><span class=\"token punctuation\">]</span>\n        exp_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>exp_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>exp_data<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>exp_col<span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span>exp_idx<span class=\"token punctuation\">)</span>\n\n    <span class=\"token decorator annotation punctuation\">@pytest<span class=\"token punctuation\">.</span>fixture</span><span class=\"token punctuation\">(</span>autouse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_pass_fixture</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> capsys<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>capsys <span class=\"token operator\">=</span> capsys\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_data_summary</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        expected_df <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>exp_df\n        result_df <span class=\"token operator\">=</span> data_summary<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>assertTrue<span class=\"token punctuation\">(</span>expected_df<span class=\"token punctuation\">.</span>equals<span class=\"token punctuation\">(</span>result_df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_display</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---- Data summary ----'</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>exp_df<span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\n        expected_stdout <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>capsys<span class=\"token punctuation\">.</span>readouterr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        display_summary<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">)</span>\n        result_stdout <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>capsys<span class=\"token punctuation\">.</span>readouterr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>expected_stdout<span class=\"token punctuation\">,</span> result_stdout<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    unittest<span class=\"token punctuation\">.</span>main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Notice the decorator <code>@pytest.fixture(autouse=True)</code> and the function it encapsulates (<code>_pass_fixture</code>). In the unit test terminology, this method is called a <a href=\"https://docs.pytest.org/en/stable/fixture.html\">fixture</a>. Fixtures are functions (or methods if you use an OOP approach), which will run before each test to which it is applied. Fixtures are used to feed some data to the tests. They fill the same objective as the <code>setUp()</code> method we used before. Here we are using a predefined fixture called <code>capsys</code> to capture the standard output (<code>stdout</code>) and reuse it in our test. We can then modify our code <code>display_summary()</code> accordingly:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">data_summary</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Function defined to output details about the number\n    of rows and columns and the column dtype frequency of\n    the passed pandas DataFrame\n    \"\"\"</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_shape</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        Function defined to return a dataframe with details about\n        the number of row and columns\n        \"\"\"</span>\n        row<span class=\"token punctuation\">,</span> col <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>shape\n        <span class=\"token keyword\">return</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Values'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Number of rows'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Number of columns'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_dtypes_freq</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        Function defined to return a dataframe with details about\n        the pandas dtypes frequency\n        \"\"\"</span>\n        counter<span class=\"token punctuation\">,</span> types <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> df<span class=\"token punctuation\">.</span>dtypes\n        <span class=\"token keyword\">for</span> dtype <span class=\"token keyword\">in</span> types<span class=\"token punctuation\">:</span>\n            tmp <span class=\"token operator\">=</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>dtype<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> tmp <span class=\"token keyword\">in</span> counter<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                counter<span class=\"token punctuation\">[</span>tmp<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                counter<span class=\"token punctuation\">[</span>tmp<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n        values <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>value<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> value <span class=\"token keyword\">in</span> counter<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">return</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token operator\">=</span>values<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Values'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>counter<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    result_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>_shape<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> _dtypes_freq<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> result_df\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">display_summary</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Function define to print out the result of the data summary\n    \"\"\"</span>\n    result_df <span class=\"token operator\">=</span> data_summary<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span>\n    message <span class=\"token operator\">=</span> <span class=\"token string\">'---- Data summary ----'</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>message<span class=\"token punctuation\">,</span> result_df<span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>Then run the tests again:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry run pytest <span class=\"token parameter variable\">-v</span>\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span> <span class=\"token builtin class-name\">test</span> session starts <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span>\nplatform linux -- Python <span class=\"token number\">3.8</span>.7, pytest-5.4.3, py-1.10.0, pluggy-0.13.1 -- /home/fbraza/.cache/pypoetry/virtualenvs/summarize-dataframe-SO-g_7pj-py3.8/bin/python\ncachedir: .pytest_cache\nrootdir: /home/fbraza/Documents/python_project/summarize_dataframe\ncollected <span class=\"token number\">2</span> items\ntests/test_summarize_dataframe.py::TestDataSummary::test_data_summary PASSED <span class=\"token punctuation\">[</span> <span class=\"token number\">50</span>%<span class=\"token punctuation\">]</span>\ntests/test_summarize_dataframe.py::TestDataSummary::test_display PASSED      <span class=\"token punctuation\">[</span><span class=\"token number\">100</span>%<span class=\"token punctuation\">]</span>\n\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span> <span class=\"token number\">2</span> passed <span class=\"token keyword\">in</span> <span class=\"token number\">0</span>.29s <span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span></code></pre></div>\n<p>The tests now succeed. It is time to commit and share our work, for example by publishing it to <a href=\"https://github.com/\">GitHub</a>. Before that, let's take a close look at how to properly communicate about our work with Git commit messages while respecting and enforcing a common standard.</p>\n<h2 id=\"enforce-git-commit-messages-rules-in-your-python-project\" style=\"position:relative;\"><a href=\"#enforce-git-commit-messages-rules-in-your-python-project\" aria-label=\"enforce git commit messages rules in your python project permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Enforce Git commit messages rules in your Python project</h2>\n<p>Writing optimal Git commit messages is not an easy task. Messages need to be clear, readable, and understandable in the long term. <strong><a href=\"https://www.conventionalcommits.org/en/v1.0.0/\">The Conventional Commits specification</a></strong> proposes a set of rules for creating explicit commit histories.</p>\n<h3 id=\"using-commitizen\" style=\"position:relative;\"><a href=\"#using-commitizen\" aria-label=\"using commitizen permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Using <code>commitizen</code></h3>\n<p>In our series about <a href=\"/fbraza-github-pages/en/2021/02/02/js-monorepos-commits-changelog/\">JavaScript monorepos</a>, we saw how to integrate these conventions to enforce good practices regarding commit messages. Applied to Python, we are going to use a package called <a href=\"https://commitizen-tools.github.io/commitizen/\">commitizen</a> to achieve this. Let's add this package to our developer dependencies:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry <span class=\"token function\">add</span> <span class=\"token parameter variable\">-D</span> commitizen\n\nUsing version ^2.17.0 <span class=\"token keyword\">for</span> commitizen\n\nUpdating dependencies\nResolving dependencies<span class=\"token punctuation\">..</span>. <span class=\"token punctuation\">(</span><span class=\"token number\">3</span>.1s<span class=\"token punctuation\">)</span>\n\nWriting lock <span class=\"token function\">file</span>\n\nPackage operations: <span class=\"token number\">11</span> installs, <span class=\"token number\">0</span> updates, <span class=\"token number\">0</span> removals\n\n  • Installing markupsafe <span class=\"token punctuation\">(</span><span class=\"token number\">1.1</span>.1<span class=\"token punctuation\">)</span>\n  • Installing prompt-toolkit <span class=\"token punctuation\">(</span><span class=\"token number\">3.0</span>.18<span class=\"token punctuation\">)</span>\n  • Installing argcomplete <span class=\"token punctuation\">(</span><span class=\"token number\">1.12</span>.2<span class=\"token punctuation\">)</span>\n  • Installing colorama <span class=\"token punctuation\">(</span><span class=\"token number\">0.4</span>.4<span class=\"token punctuation\">)</span>\n  • Installing decli <span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span>.2<span class=\"token punctuation\">)</span>\n  • Installing jinja2 <span class=\"token punctuation\">(</span><span class=\"token number\">2.11</span>.3<span class=\"token punctuation\">)</span>\n  • Installing pyyaml <span class=\"token punctuation\">(</span><span class=\"token number\">5.4</span>.1<span class=\"token punctuation\">)</span>\n  • Installing questionary <span class=\"token punctuation\">(</span><span class=\"token number\">1.6</span>.0<span class=\"token punctuation\">)</span>\n  • Installing termcolor <span class=\"token punctuation\">(</span><span class=\"token number\">1.1</span>.0<span class=\"token punctuation\">)</span>\n  • Installing tomlkit <span class=\"token punctuation\">(</span><span class=\"token number\">0.7</span>.0<span class=\"token punctuation\">)</span>\n  • Installing commitizen <span class=\"token punctuation\">(</span><span class=\"token number\">2.17</span>.0<span class=\"token punctuation\">)</span></code></pre></div>\n<p>To setup <code>commitizen</code> for your project, run the command <code>cz init</code>. It prompts us with a set of questions:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cz init\n? Please choose a supported config file: <span class=\"token punctuation\">(</span>default: pyproject.toml<span class=\"token punctuation\">)</span>  <span class=\"token punctuation\">(</span>Use arrow keys<span class=\"token punctuation\">)</span>\n » pyproject.toml\n   .cz.toml\n   .cz.json\n   cz.json\n   .cz.yaml\n   cz.yaml\n\n? Please choose a cz <span class=\"token punctuation\">(</span>commit rule<span class=\"token punctuation\">)</span>: <span class=\"token punctuation\">(</span>default: cz_conventional_commits<span class=\"token punctuation\">)</span>  <span class=\"token punctuation\">(</span>Use arrow keys<span class=\"token punctuation\">)</span>\n » cz_conventional_commits\n   cz_jira\n   cz_customize\n\n? Please enter the correct version format: <span class=\"token punctuation\">(</span>default: <span class=\"token string\">\"<span class=\"token variable\">$version</span>\"</span><span class=\"token punctuation\">)</span>\n\n? Do you want to <span class=\"token function\">install</span> pre-commit hook?  <span class=\"token punctuation\">(</span>Y/n<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Choose all default choices here as they fit perfectly with our actual situation. The last question asks us if we want to use <a href=\"https://pre-commit.com/\">pre-commit</a> hook. We are going to come back to this later on. So just answer <code>no</code> for now. If we look at our <code>pyproject.toml</code> file we can see that a new entry named <code>[tool.commitizen]</code> has been added:</p>\n<div class=\"gatsby-highlight\" data-language=\"ini\"><pre class=\"language-ini\"><code class=\"language-ini\"><span class=\"token section\"><span class=\"token punctuation\">[</span><span class=\"token section-name selector\">...</span><span class=\"token punctuation\">]</span></span>\n\n<span class=\"token section\"><span class=\"token punctuation\">[</span><span class=\"token section-name selector\">tool.commitizen</span><span class=\"token punctuation\">]</span></span>\n<span class=\"token key attr-name\">name</span> <span class=\"token punctuation\">=</span> <span class=\"token value attr-value\">\"cz_conventional_commits\" # commit rule chosen</span>\n<span class=\"token key attr-name\">version</span> <span class=\"token punctuation\">=</span> <span class=\"token value attr-value\">\"<span class=\"token inner-value\">0.0.1</span>\"</span>\n<span class=\"token key attr-name\">tag_format</span> <span class=\"token punctuation\">=</span> <span class=\"token value attr-value\">\"<span class=\"token inner-value\">$version</span>\"</span></code></pre></div>\n<p>To check your commit message, you can use the following command:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cz check <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"all summarize_data tests now succeed\"</span>\n\ncommit validation: failed<span class=\"token operator\">!</span>\nplease enter a commit message <span class=\"token keyword\">in</span> the commitizen format.\ncommit <span class=\"token string\">\"\"</span><span class=\"token builtin class-name\">:</span> <span class=\"token string\">\"all summarize_data tests now succeed\"</span>\npattern: <span class=\"token punctuation\">(</span>build<span class=\"token operator\">|</span>ci<span class=\"token operator\">|</span>docs<span class=\"token operator\">|</span>feat<span class=\"token operator\">|</span>fix<span class=\"token operator\">|</span>perf<span class=\"token operator\">|</span>refactor<span class=\"token operator\">|</span>style<span class=\"token operator\">|</span><span class=\"token builtin class-name\">test</span><span class=\"token operator\">|</span>chore<span class=\"token operator\">|</span>revert<span class=\"token operator\">|</span>bump<span class=\"token punctuation\">)</span><span class=\"token operator\">!</span>?<span class=\"token punctuation\">(</span><span class=\"token punctuation\">\\</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">\\</span>S+<span class=\"token punctuation\">\\</span><span class=\"token punctuation\">))</span>?:<span class=\"token punctuation\">(</span><span class=\"token punctuation\">\\</span>s.*<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Our message is rejected because it does not respect the commit rules. The last line suggests some patterns to use. Take some time to read the <a href=\"https://www.conventionalcommits.org/en/v1.0.0/\">conventional commits</a> documentation and run the command <code>cz info</code> to print a short documentation:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cz info\nThe commit contains the following structural elements, to communicate intent to the consumers of your library:\n\nfix: a commit of the <span class=\"token builtin class-name\">type</span> fix patches a bug <span class=\"token keyword\">in</span> your codebase\n<span class=\"token punctuation\">(</span>this correlates with PATCH <span class=\"token keyword\">in</span> semantic versioning<span class=\"token punctuation\">)</span>.\n\nfeat: a commit of the <span class=\"token builtin class-name\">type</span> feat introduces a new feature to the codebase\n<span class=\"token punctuation\">(</span>this correlates with MINOR <span class=\"token keyword\">in</span> semantic versioning<span class=\"token punctuation\">)</span>.\n\nBREAKING CHANGE: a commit that has the text BREAKING CHANGE: at the beginning of\nits optional body or footer section introduces a breaking API change\n<span class=\"token punctuation\">(</span>correlating with MAJOR <span class=\"token keyword\">in</span> semantic versioning<span class=\"token punctuation\">)</span>.\nA BREAKING CHANGE can be part of commits of any type.\n\nOthers: commit types other than fix: and feat: are allowed,\nlike chore:, docs:, style:, refactor:, perf:, test:, and others.\n<span class=\"token punctuation\">[</span><span class=\"token punctuation\">..</span>.<span class=\"token punctuation\">]</span></code></pre></div>\n<p>This command guides you on how to write your commit message. Here the format should be <code>\"[pattern]: [MESSAGE]\"</code>. For us, this leads to:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cz check <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"test: all summarize_data tests now succeed\"</span>\nCommit validation: successful<span class=\"token operator\">!</span></code></pre></div>\n<p>Very good, our commit message is valid. But hold on. Checking our messages each time with <code>commitizen</code> might be cumbersome and doesn't provide the garanty to be applied. It would be better to check automatically the message each time we use the <code>git commit</code> command. That is where the <code>pre-commit</code> hook takes action.</p>\n<h3 id=\"automatically-enforce-git-message-conventions-with-pre-commit\" style=\"position:relative;\"><a href=\"#automatically-enforce-git-message-conventions-with-pre-commit\" aria-label=\"automatically enforce git message conventions with pre commit permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Automatically enforce Git message conventions with <code>pre-commit</code></h3>\n<p>Git hooks are useful to automate and perform some actions at specific place during the Git lifecycle. The <code>pre-commit</code> hook permits to run scripts before a Git commit is issued. We can use the hook to validate the commit messages and prevent Git from using a message which doesn't match our expectations. The hook is active from the command line as well as from any tools interacting with the Git repository where the hook is registered, including your favoride IDE.</p>\n<p><a href=\"https://pre-commit.com/index.html\">pre-commit</a> is a framework for managing and maintaining multi-language pre-commit hooks. If you want to know more about the inner workings and the spectrum of possibilities opened by the <code>pre-commit</code> hook, you can read its <a href=\"https://pre-commit.com/index.html#usage\">usage documentation</a>.</p>\n<p>To install <code>pre-commit</code> just run:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">peotry <span class=\"token function\">add</span> <span class=\"token parameter variable\">-D</span> pre-commit</code></pre></div>\n<p>To automate the Git commit verification we first need to create a configuration file <code>.pre-commit-config.yaml</code> as followed:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token punctuation\">---</span>\n<span class=\"token key atrule\">repos</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">repo</span><span class=\"token punctuation\">:</span> https<span class=\"token punctuation\">:</span>//github.com/commitizen<span class=\"token punctuation\">-</span>tools/commitizen\n    <span class=\"token key atrule\">rev</span><span class=\"token punctuation\">:</span> master\n    <span class=\"token key atrule\">hooks</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">id</span><span class=\"token punctuation\">:</span> commitizen\n        <span class=\"token key atrule\">stages</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>commit<span class=\"token punctuation\">-</span>msg<span class=\"token punctuation\">]</span></code></pre></div>\n<p>Next we can install the hook with its source defined in the <code>repo</code> property:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">pre-commit <span class=\"token function\">install</span> --hook-type commit-msg</code></pre></div>\n<p>Now that everything is set, we can use our Git hook:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> commit <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"test: all summarize_data tests now succeed\"</span>\n<span class=\"token punctuation\">[</span>INFO<span class=\"token punctuation\">]</span> Initializing environment <span class=\"token keyword\">for</span> https://github.com/commitizen-tools/commitizen.\n<span class=\"token punctuation\">[</span>INFO<span class=\"token punctuation\">]</span> Installing environment <span class=\"token keyword\">for</span> https://github.com/commitizen-tools/commitizen.\n<span class=\"token punctuation\">[</span>INFO<span class=\"token punctuation\">]</span> Once installed this environment will be reused.\n<span class=\"token punctuation\">[</span>INFO<span class=\"token punctuation\">]</span> This may take a few minutes<span class=\"token punctuation\">..</span>.\ncommitizen check<span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span>.Passed\n<span class=\"token punctuation\">[</span>INFO<span class=\"token punctuation\">]</span> Restored changes from /home/fbraza/.cache/pre-commit/patch1617970841.\n<span class=\"token punctuation\">[</span>master 1e64d0a<span class=\"token punctuation\">]</span> test: all summarize_data tests now succeed\n <span class=\"token number\">2</span> files changed, <span class=\"token number\">48</span> insertions<span class=\"token punctuation\">(</span>+<span class=\"token punctuation\">)</span>, <span class=\"token number\">5</span> deletions<span class=\"token punctuation\">(</span>-<span class=\"token punctuation\">)</span>\n rewrite tests/test_summarize_dataframe.py <span class=\"token punctuation\">(</span><span class=\"token number\">98</span>%<span class=\"token punctuation\">)</span></code></pre></div>\n<p><code>pre-commit</code> installs an environment to run its checks. As you can see here the commit message assessment passed. To finish we can commit and push the modifications made on the build files (<code>poetry.lock</code>, <code>pyproject.toml</code>) and our module:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> commit <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"build: add developer dependencies\"</span> <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"commitizen and pre-commit added to our dev dependencies\"</span>\n\ncommitizen check<span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span>.Passed\n<span class=\"token punctuation\">[</span>master 1c6457c<span class=\"token punctuation\">]</span> build: <span class=\"token function\">add</span> developer dependencies\n <span class=\"token number\">2</span> files changed, <span class=\"token number\">585</span> insertions<span class=\"token punctuation\">(</span>+<span class=\"token punctuation\">)</span>, <span class=\"token number\">1</span> deletion<span class=\"token punctuation\">(</span>-<span class=\"token punctuation\">)</span>\n\n <span class=\"token function\">git</span> commit <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"feat: implementation of the summary function to summarize dataframe\"</span>\n\ncommitizen check<span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span>.Passed\n<span class=\"token punctuation\">[</span>master 5c053ad<span class=\"token punctuation\">]</span> build: <span class=\"token function\">add</span> developer dependencies\n <span class=\"token number\">1</span> <span class=\"token function\">file</span> changed, <span class=\"token number\">94</span> insertions<span class=\"token punctuation\">(</span>+<span class=\"token punctuation\">)</span></code></pre></div>\n<p>We can now push everything to our GitHub repository:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> push origin master</code></pre></div>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>We covered a few topics:</p>\n<ul>\n<li>On the first hand, we saw how to write unit tests for your code. You shall always start to write tests before coding. It helps you affinate your API and expectations before implementing them. You will definitively benefit from it. We used <code>unittest</code> which is already available in the Python standard library. I actually like its simple design and object-oriented approach but others prefer using the <a href=\"https://docs.pytest.org/en/stable/\"><code>pytest</code> library</a> which is definitively worth checking. One very convenient aspect is that <code>pytest</code> supports the <code>unittest.TestCase</code> class from the beginning. You can then write your tests with either of the two libraries or even mix both depending on your needs and have one common command to run them all.</li>\n<li>We saw how to enforce good practices when writing Git commit messages. Our proposed solution relies on the use of two distinct Python packages: <a href=\"https://commitizen-tools.github.io/commitizen/\">commitizen</a> and <a href=\"https://pre-commit.com/\">pre-commit</a>. The first one provides with the tools to check if a message validate the conventions you have chosen. The second one automates the process using a Git hook.</li>\n</ul>\n<p>In our next and last article, we are going to go one step further. We automate testing using <code>tox</code> and integrate it inside a <a href=\"/fbraza-github-pages/en/tag/ci-cd/\">CI/CD</a> pipeline. Once done we will show how to prepare our package and finally publish it on <a href=\"https://pypi.org/\">PyPi</a> using <code>poetry</code>.</p>\n<h2 id=\"cheat-sheet\" style=\"position:relative;\"><a href=\"#cheat-sheet\" aria-label=\"cheat sheet permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cheat sheet</h2>\n<h3 id=\"poetry\" style=\"position:relative;\"><a href=\"#poetry\" aria-label=\"poetry permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code>poetry</code></h3>\n<ul>\n<li>\n<p>Add project dependencies:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry <span class=\"token function\">add</span> <span class=\"token punctuation\">[</span>package_name<span class=\"token punctuation\">]</span></code></pre></div>\n</li>\n<li>\n<p>Add developer dependencies:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry <span class=\"token function\">add</span> <span class=\"token parameter variable\">-D</span> <span class=\"token punctuation\">[</span>package_name<span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry <span class=\"token function\">add</span> <span class=\"token parameter variable\">--dev</span> <span class=\"token punctuation\">[</span>package_name<span class=\"token punctuation\">]</span></code></pre></div>\n</li>\n<li>\n<p>Run test:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">poetry run pytest</code></pre></div>\n</li>\n</ul>\n<h3 id=\"commitizen\" style=\"position:relative;\"><a href=\"#commitizen\" aria-label=\"commitizen permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code>commitizen</code></h3>\n<ul>\n<li>\n<p>Initialize <code>commitizen</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cz init</code></pre></div>\n</li>\n<li>\n<p>Check your commit:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">cz check <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"YOUR MESSAGE\"</span></code></pre></div>\n</li>\n</ul>\n<h3 id=\"pre-commit\" style=\"position:relative;\"><a href=\"#pre-commit\" aria-label=\"pre commit permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code>pre-commit</code></h3>\n<ul>\n<li>\n<p>Generate a default configuration file:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">pre-commit sample-config</code></pre></div>\n</li>\n<li>\n<p>Install git hook:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">pre-commit <span class=\"token function\">install</span> --hook-type <span class=\"token punctuation\">[</span>hook_name<span class=\"token punctuation\">]</span></code></pre></div>\n</li>\n</ul>\n<h2 id=\"acknowledgments\" style=\"position:relative;\"><a href=\"#acknowledgments\" aria-label=\"acknowledgments permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Acknowledgments</h2>\n<p>This article was first published in Adaltas <a href=\"https://www.adaltas.com/en/articles/\">blog</a> and kindly reviewed by the CEO David Worms and one consultant Barthelemy NGOM.</p>","frontmatter":{"title":"Modern Python part 2: write unit tests & enforce Git commit conventions","date":"June 24, 2021","tags":["Python","Github","DevOps"]}}},"pageContext":{"id":"bd6e1d88-5087-52e1-a3f6-9fe9a4d14ee3","fields__slug":"/modern-python-part2/","__params":{"fields__slug":"modern-python-part2"}}},"staticQueryHashes":["2750728228"],"slicesMap":{}}